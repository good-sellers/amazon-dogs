#!/usr/bin/env python3
"""
ä¸ºç²¾ç¡®æ¸…æ´—åçš„å›¾ç‰‡ç”Ÿæˆç´¢å¼•æ–‡ä»¶
"""

import json
import os
from pathlib import Path
from datetime import datetime

def generate_cleaned_index():
    """ç”Ÿæˆæ¸…æ´—åå›¾ç‰‡çš„ç´¢å¼•æ–‡ä»¶"""
    # è¯»å–åŸå§‹ç´¢å¼•æ–‡ä»¶
    original_index_path = Path("data/dogs/index.json")
    cleaned_images_dir = Path("data/precise_cleaned/images")
    cleaned_index_path = Path("data/precise_cleaned/index.json")
    
    if not original_index_path.exists():
        print(f"åŸå§‹ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {original_index_path}")
        return
    
    if not cleaned_images_dir.exists():
        print(f"æ¸…æ´—åå›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {cleaned_images_dir}")
        return
    
    # è¯»å–åŸå§‹ç´¢å¼•
    with open(original_index_path, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    # åˆ›å»ºæ–°çš„ç´¢å¼•æ•°æ®
    cleaned_data = {
        "total_images": 0,
        "images": [],
        "created_at": datetime.now().isoformat(),
        "description": "ç²¾ç¡®æ¸…æ´—åçš„ç‹—ç‹—å›¾ç‰‡ - å·²å»é™¤è“è‰²æ°´å°",
        "source": "Amazon Dogs Images - Watermark Cleaned"
    }
    
    # éå†åŸå§‹å›¾ç‰‡ä¿¡æ¯
    for original_image in original_data["images"]:
        # æ„å»ºæ¸…æ´—åå›¾ç‰‡çš„æ–‡ä»¶è·¯å¾„
        cleaned_filename = f"precise_{original_image['filename']}"
        cleaned_file_path = cleaned_images_dir / cleaned_filename
        
        # æ£€æŸ¥æ¸…æ´—åçš„å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        if cleaned_file_path.exists():
            # è·å–æ–‡ä»¶å¤§å°
            file_size = cleaned_file_path.stat().st_size
            
            # åˆ›å»ºæ–°çš„å›¾ç‰‡ä¿¡æ¯
            cleaned_image = {
                "number": original_image["number"],
                "filename": cleaned_filename,
                "url": original_image["url"],  # ä¿ç•™åŸå§‹URLä½œä¸ºå¤‡ç”¨
                "size": file_size,
                "original_filename": original_image["filename"],
                "original_size": original_image["size"],
                "watermark_removed": True
            }
            
            cleaned_data["images"].append(cleaned_image)
            cleaned_data["total_images"] += 1
            
            print(f"âœ… å¤„ç†å›¾ç‰‡ {original_image['number']}: {cleaned_filename} ({file_size} bytes)")
        else:
            print(f"âŒ æ¸…æ´—åå›¾ç‰‡ä¸å­˜åœ¨: {cleaned_filename}")
    
    # ä¿å­˜æ–°çš„ç´¢å¼•æ–‡ä»¶
    cleaned_index_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(cleaned_index_path, 'w', encoding='utf-8') as f:
        json.dump(cleaned_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ æ¸…æ´—åç´¢å¼•æ–‡ä»¶å·²ä¿å­˜: {cleaned_index_path}")
    print(f"ğŸ“Š æ€»è®¡å¤„ç†å›¾ç‰‡: {cleaned_data['total_images']} å¼ ")
    
    # åˆ›å»ºå‰ç«¯ public ç›®å½•çš„ç´¢å¼•å‰¯æœ¬
    frontend_public_path = Path("frontend/public/cleaned_index.json")
    frontend_public_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(frontend_public_path, 'w', encoding='utf-8') as f:
        json.dump(cleaned_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ å‰ç«¯ç´¢å¼•æ–‡ä»¶å·²ä¿å­˜: {frontend_public_path}")

if __name__ == "__main__":
    generate_cleaned_index() 